{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f18ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad04bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import docx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9130a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "PATH_ACTION_POINTS = Path(\"Action Points GSS 2025.docx\")\n",
    "PATH_T20 = Path(\"T20 communique.docx\")\n",
    "\n",
    "# SBERT model \n",
    "SBERT_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# How many top T20 matches to show for each action point\n",
    "TOP_K = 3\n",
    "\n",
    "# Output HTML file\n",
    "OUT_HTML = Path(\"gss_t20_similarity.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e776b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx_paragraphs(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path.resolve()}\")\n",
    "    doc = docx.Document(str(path))\n",
    "    paras = [p.text.strip() for p in doc.paragraphs]\n",
    "    return [p for p in paras if p.strip()]\n",
    "\n",
    "def looks_like_cluster_header(line: str) -> bool:\n",
    "    if not line: return False\n",
    "    if line.startswith(\"[\"): return False\n",
    "    if line.lstrip().startswith(\"- \"): return False\n",
    "    if re.match(r\"^\\d+(\\.|:)?\\s\", line): return False\n",
    "    return True\n",
    "\n",
    "def parse_gss_clusters(paragraphs):\n",
    "    clusters = defaultdict(list)\n",
    "    current_cluster = None\n",
    "    for line in paragraphs:\n",
    "        txt = line.strip()\n",
    "        if not txt: \n",
    "            continue\n",
    "        if looks_like_cluster_header(txt) and not txt.startswith(\"[]\"):\n",
    "            current_cluster = txt\n",
    "            _ = clusters[current_cluster]  # ensure key\n",
    "            continue\n",
    "        if txt.startswith(\"[]\") or (\"[\" in txt and \"]\" in txt):\n",
    "            ap = re.sub(r\"^\\s*\\[\\s*\\]\\s*\", \"\", txt).strip()\n",
    "            if not current_cluster:\n",
    "                current_cluster = \"Ungrouped\"\n",
    "            if ap:\n",
    "                clusters[current_cluster].append(ap)\n",
    "    # drop empty clusters\n",
    "    return {k: v for k, v in clusters.items() if v}\n",
    "\n",
    "def normalize_whitespace(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def split_t20_into_sentences(paragraphs):\n",
    "    sentences = []\n",
    "    current_section = None\n",
    "    for raw in paragraphs:\n",
    "        line = raw.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # treat title-ish lines as sections (no period at end)\n",
    "        if looks_like_cluster_header(line) and not line.endswith(\".\"):\n",
    "            current_section = line\n",
    "            continue\n",
    "        for s in sent_tokenize(line):\n",
    "            s = normalize_whitespace(s)\n",
    "            if len(s) >= 3:\n",
    "                sentences.append({\"sentence\": s, \"section\": current_section})\n",
    "    # dedupe\n",
    "    seen, out = set(), []\n",
    "    for row in sentences:\n",
    "        key = (row[\"sentence\"], row[\"section\"])\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            out.append(row)\n",
    "    return out\n",
    "\n",
    "def embed_texts(model, texts):\n",
    "    return model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "def build_html(results_by_cluster):\n",
    "    css = \"\"\"\n",
    "    <style>\n",
    "      body { font-family: system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif; margin: 24px; color: #111; }\n",
    "      h1 { font-size: 28px; margin-bottom: 8px; }\n",
    "      h2 { font-size: 22px; margin-top: 28px; }\n",
    "      .note { color: #555; margin-bottom: 24px; }\n",
    "      table { border-collapse: collapse; width: 100%; margin: 12px 0 28px 0; }\n",
    "      th, td { border: 1px solid #e5e7eb; padding: 10px 12px; vertical-align: top; }\n",
    "      th { background: #f8fafc; text-align: left; font-weight: 600; }\n",
    "      tr:nth-child(even) { background: #fafafa; }\n",
    "      .ap { font-weight: 600; }\n",
    "      .section { color: #444; font-size: 12px; margin-top: 4px; }\n",
    "      .score { font-variant-numeric: tabular-nums; }\n",
    "      .cluster-badge { display:inline-block; background:#eef2ff; color:#3730a3; padding:4px 8px; border-radius:12px; font-size:12px; margin-left:6px; }\n",
    "      .footer { margin-top: 40px; color: #666; font-size: 12px; }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    html = [f\"<!DOCTYPE html><html><head><meta charset='utf-8'><title>GSS–T20 Similarity</title>{css}</head><body>\"]\n",
    "    html.append(\"<h1>GSS 2025 Action Points ↔ T20 Recommendations</h1>\")\n",
    "    html.append(\"<div class='note'>Scores are cosine similarities (Sentence-BERT). Range: 0–1.</div>\")\n",
    "    for cluster, df in results_by_cluster.items():\n",
    "        html.append(f\"<h2>{cluster} <span class='cluster-badge'>Top matches</span></h2>\")\n",
    "        html.append(\"<table>\")\n",
    "        html.append(\"<tr><th style='width:32%'>Action Point</th><th>Match (T20 Sentence)</th><th style='width:8%'>Rank</th><th style='width:10%'>Score</th></tr>\")\n",
    "        last_ap_idx = None\n",
    "        for _, r in df.sort_values([\"ap_index\", \"rank\"]).iterrows():\n",
    "            ap_cell = \"\"\n",
    "            if r[\"ap_index\"] != last_ap_idx:\n",
    "                ap_cell = f\"<div class='ap'>{r['action_point']}</div>\"\n",
    "                last_ap_idx = r[\"ap_index\"]\n",
    "            section_badge = f\"<div class='section'>Section: {r['t20_section']}</div>\" if pd.notna(r['t20_section']) and r['t20_section'] else \"\"\n",
    "            html.append(\n",
    "                \"<tr>\"\n",
    "                f\"<td>{ap_cell}</td>\"\n",
    "                f\"<td>{r['t20_sentence']}{section_badge}</td>\"\n",
    "                f\"<td class='score'>{int(r['rank'])}</td>\"\n",
    "                f\"<td class='score'>{r['score']:.3f}</td>\"\n",
    "                \"</tr>\"\n",
    "            )\n",
    "        html.append(\"</table>\")\n",
    "    html.append(\"<div class='footer'>Model: SentenceTransformer ‘all-MiniLM-L6-v2’. Adjust TOP_K and model in the config cell.</div>\")\n",
    "    html.append(\"</body></html>\")\n",
    "    return \"\\n\".join(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732e7dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSS paragraphs: 32\n",
      "GSS sample: ['Human Flourishing', '[] Champion a global narrative shift from economic growth to human flourishing, grounded in equity, sustainability, and dignity.', '[] Reform financial systems to support inclusive, long-term development.', '[] Empower communities to co-create solutions, especially in the Global South, through grassroots innovation and development corridors', '[] Leverage the influence of G20: Use the G20 as a platform for piloting and scaling flourishing-centered models.', 'Climate Action and Sustainability', '[]  Reform global finance systems\\xa0to reduce the cost of capital in the Global South, mobilize private investment, and support inclusive, long-term climate and development goals.', '[] Scale community-led and grassroots solutions\\xa0by integrating them into national strategies, enabling direct access to funding, and supporting blended finance and SPV models.']\n",
      "------------------------------------------------------------\n",
      "T20 paragraphs: 23\n",
      "T20 sample: ['Trade and Investment', '1.1. Empower the WTO to preserve and reform the multilateral trading system: The G20 should empower the WTO by strengthening the WTO Secretariat and making additional financial resources available. The decision-making process should also be made more flexible, this will help advance and incorporate pro-development plurilateral agreements, such as the Investment Facilitation for Development (IFD) Agreement, into the WTO Framework. The dispute settlement system needs to be reformed to strengthen deliberative processes and preventive mechanisms, in the interim building on the Multi-Party Interim Appeal Arbitration Arrangement (MPIA).', 'The Generalised System of Preferences (GSP) should be reviewed to provide predictable, longterm market access for services and flexible rules of origin for goods for Least Developed Countries (LDCs). The G20 should build consensus and momentum to the 14th Ministerial Conference of the WTO (MC14) around the GSP reform.', '1.2. Promote a coordinated approach to regional trade cooperation that harmonises physical, social, and digital infrastructures and standards, and promote interoperability of trade systems to reduce asymmetries: The G20 should support coordination across its working groups on strengthening regional integration initiatives, for example those focused on intra-African trade and economic transformation. The G20 should address intra- and inter- country asymmetries through people-centred investment financing and Public-Private Partnerships (PPPs), including energy transmission and transport networks, digital and social infrastructure.', '1.3. Promote industrial and investment policy to support a just and green transition and economic growth through value chain integration, and the transfer of innovative technologies: The G20 should support the creation of shared data and traceability systems. The rules of trade and investment should provide space for countries to pursue value-addition and technology transfer with instruments and incentives that are time-bound and transparent. The G20 members should uphold their commitments to use subsidies only for permissible development objectives.', 'Digital Transformation', '2.1. Drive efforts to fund the production of standard and new statistics and analysis necessary for evidence-based digital policy: The G20 should drive efforts to fund the production of digital statistics and analysis necessary for evidence-based policy, which is crucial for addressing foundational digital inequalities, such inequality undermines the potential of emerging technologies (such as AI systems) to address planetary problems. 2.2. Align with global governance efforts to support the development of enabling national and regional integrated data governance frameworks: The G20 should support the development of enabling national and regional integrated data governance frameworks that are holistic, rightspromoting, equitable and just. Data governance is a cross-cutting issue that will require the review of existing institutional arrangements that are not fit-for-purpose for this dynamic and complex environment. Data governance is required not only to safeguard citizens from harms associated largely with privacy protection and personal data but also to redress the uneven distribution of opportunities associated with advanced data-driven technologies and systems, such as AI, and in the deployment of DPI to enable more equitable digital inclusion.', '2.3. Extend earlier G20 endorsements of the role of Digital Public Infrastructure in development with commitments to ensuring a ‘people-first’ and whole-of-society approach to digital public infrastructure and emerging technologies: The design and implementation of technologies remain uneven, exclusionary and unequal. The G20 should play a leading role in advocating for global forums on digital technology for sustainable development, focusing on achieving more sustainable and inclusive digital futures, this includes a shift in process towards realising more participatory data governance and incorporating offline, multilingual and assisted options.']\n"
     ]
    }
   ],
   "source": [
    "# Open the two Word docs \n",
    "gss_paragraphs = read_docx_paragraphs(PATH_ACTION_POINTS)\n",
    "t20_paragraphs = read_docx_paragraphs(PATH_T20)\n",
    "\n",
    "print(f\"GSS paragraphs: {len(gss_paragraphs)}\")\n",
    "print(\"GSS sample:\", gss_paragraphs[:8])  # preview a few lines\n",
    "print(\"-\" * 60)\n",
    "print(f\"T20 paragraphs: {len(t20_paragraphs)}\")\n",
    "print(\"T20 sample:\", t20_paragraphs[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4883af6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected clusters: 6\n",
      " • Human Flourishing: 4 action points\n",
      " • Climate Action and Sustainability: 5 action points\n",
      " • Digital and AI Transformation: 5 action points\n",
      " • Geoeconomics and Trade: 4 action points\n",
      " • Global Finance: 4 action points\n",
      " • Global Governance and Multilateralism: 4 action points\n",
      "\n",
      "First cluster preview: Human Flourishing\n",
      " - Champion a global narrative shift from economic growth to human flourishing, grounded in equity, sustainability, and dignity.\n",
      " - Reform financial systems to support inclusive, long-term development.\n",
      " - Empower communities to co-create solutions, especially in the Global South, through grassroots innovation and development corridors\n"
     ]
    }
   ],
   "source": [
    "# Parse clusters and action points \n",
    "gss_clusters = parse_gss_clusters(gss_paragraphs)\n",
    "print(f\"Detected clusters: {len(gss_clusters)}\")\n",
    "for k, v in gss_clusters.items():\n",
    "    print(f\" • {k}: {len(v)} action points\")\n",
    "#  first cluster details\n",
    "first_cluster = next(iter(gss_clusters)) if gss_clusters else None\n",
    "if first_cluster:\n",
    "    print(\"\\nFirst cluster preview:\", first_cluster)\n",
    "    for ap in gss_clusters[first_cluster][:3]:\n",
    "        print(\" -\", ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03b207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T20 sentences: 62\n",
      "T20 sentence sample:\n",
      " - {'sentence': '1.1.', 'section': 'Trade and Investment'}\n",
      " - {'sentence': 'Empower the WTO to preserve and reform the multilateral trading system: The G20 should empower the WTO by strengthening the WTO Secretariat and making additional financial resources available.', 'section': 'Trade and Investment'}\n",
      " - {'sentence': 'The decision-making process should also be made more flexible, this will help advance and incorporate pro-development plurilateral agreements, such as the Investment Facilitation for Development (IFD) Agreement, into the WTO Framework.', 'section': 'Trade and Investment'}\n",
      " - {'sentence': 'The dispute settlement system needs to be reformed to strengthen deliberative processes and preventive mechanisms, in the interim building on the Multi-Party Interim Appeal Arbitration Arrangement (MPIA).', 'section': 'Trade and Investment'}\n",
      " - {'sentence': 'The Generalised System of Preferences (GSP) should be reviewed to provide predictable, longterm market access for services and flexible rules of origin for goods for Least Developed Countries (LDCs).', 'section': 'Trade and Investment'}\n"
     ]
    }
   ],
   "source": [
    "#  Split T20 into sentences \n",
    "t20_sent_rows = split_t20_into_sentences(t20_paragraphs)\n",
    "print(f\"T20 sentences: {len(t20_sent_rows)}\")\n",
    "print(\"T20 sentence sample:\")\n",
    "for r in t20_sent_rows[:5]:\n",
    "    print(\" -\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1fb45b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SBERT: sentence-transformers/all-MiniLM-L6-v2\n",
      "T20 embedding shape: (62, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Sentence-BERT model \n",
    "model = SentenceTransformer(SBERT_MODEL)\n",
    "print(\"Loaded SBERT:\", SBERT_MODEL)\n",
    "\n",
    "# Embed T20 sentences \n",
    "t20_sentences = [r[\"sentence\"] for r in t20_sent_rows]\n",
    "t20_sections = [r[\"section\"] for r in t20_sent_rows]\n",
    "t20_emb = embed_texts(model, t20_sentences)\n",
    "print(\"T20 embedding shape:\", t20_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc26fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing cluster: Human Flourishing | APs: 4\n",
      "\n",
      "Action Point: Champion a global narrative shift from economic growth to human flourishing, grounded in equity, sustainability, and dignity.\n",
      "  1. (0.487) Champion comprehensive ‘whole-of society, whole-of-economy’ just transition taxonomies, and exercise political leadership in UNFCCC negotiations to secure concrete outcomes and the means of implementation for just transitions at global and local levels: The G20 should lead on local, national, regional and international just transition policies and taxonomies in line with a ‘whole-of-government, whole-of-society’ approach that pursue, among others, poverty alleviation, social equity and resilience, gender equality and economic empowerment. | Section: Accelerating Climate Action and the Just Energy Transition\n",
      "  2. (0.453) Operationalise the Global Alliance Against Hunger and Poverty and Build Equitable Food Systems: The G20 must monitor and evaluate the operationalisation of the Global Alliance which involves mobilising all countries to join the Alliance and support the development and implementation of concrete national action plans with clear, measurable milestones, especially in low- and middle-income countries. | Section: Solidarity for the Achievement of the Sustainable Development Goals\n",
      "  3. (0.426) Take actions to bring down the cost of capital: The G20 should support a revised IMF Debt Sustainability Framework (jointly with the World Bank in the case of the framework for Low Income Countries) that incorporates assets created by debt; the costs of climate change and biodiversity collapse; and accounts for policy actions and investments to mitigate those vulnerabilities. | Section: Financing for Sustainable Development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "#  Test one cluster before running all \n",
    "test_cluster = first_cluster  \n",
    "if test_cluster:\n",
    "    ap_texts = gss_clusters[test_cluster]\n",
    "    ap_emb = embed_texts(model, ap_texts)\n",
    "    sims = cosine_similarity(ap_emb, t20_emb)  # [n_ap, n_t20]\n",
    "    print(f\"Testing cluster: {test_cluster} | APs: {len(ap_texts)}\")\n",
    "    # Top matches for the first action point only\n",
    "    ap_idx = 0\n",
    "    top_idx = np.argsort(-sims[ap_idx])[:TOP_K]\n",
    "    print(\"\\nAction Point:\", ap_texts[ap_idx])\n",
    "    for rank, ti in enumerate(top_idx, start=1):\n",
    "        print(f\"  {rank}. ({sims[ap_idx][ti]:.3f})\", t20_sentences[ti], \"| Section:\", t20_sections[ti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b43a08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results size: (78, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>ap_index</th>\n",
       "      <th>action_point</th>\n",
       "      <th>rank</th>\n",
       "      <th>t20_sentence</th>\n",
       "      <th>t20_section</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human Flourishing</td>\n",
       "      <td>0</td>\n",
       "      <td>Champion a global narrative shift from economi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Champion comprehensive ‘whole-of society, whol...</td>\n",
       "      <td>Accelerating Climate Action and the Just Energ...</td>\n",
       "      <td>0.487384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human Flourishing</td>\n",
       "      <td>0</td>\n",
       "      <td>Champion a global narrative shift from economi...</td>\n",
       "      <td>2</td>\n",
       "      <td>Operationalise the Global Alliance Against Hun...</td>\n",
       "      <td>Solidarity for the Achievement of the Sustaina...</td>\n",
       "      <td>0.453438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human Flourishing</td>\n",
       "      <td>0</td>\n",
       "      <td>Champion a global narrative shift from economi...</td>\n",
       "      <td>3</td>\n",
       "      <td>Take actions to bring down the cost of capital...</td>\n",
       "      <td>Financing for Sustainable Development</td>\n",
       "      <td>0.425814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Human Flourishing</td>\n",
       "      <td>1</td>\n",
       "      <td>Reform financial systems to support inclusive,...</td>\n",
       "      <td>1</td>\n",
       "      <td>Finance SDG Gaps through a Reform of the Globa...</td>\n",
       "      <td>Solidarity for the Achievement of the Sustaina...</td>\n",
       "      <td>0.483550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Human Flourishing</td>\n",
       "      <td>1</td>\n",
       "      <td>Reform financial systems to support inclusive,...</td>\n",
       "      <td>2</td>\n",
       "      <td>In addition, strengthened South–South and Nort...</td>\n",
       "      <td>Accelerating Climate Action and the Just Energ...</td>\n",
       "      <td>0.435472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cluster  ap_index  \\\n",
       "0  Human Flourishing         0   \n",
       "1  Human Flourishing         0   \n",
       "2  Human Flourishing         0   \n",
       "3  Human Flourishing         1   \n",
       "4  Human Flourishing         1   \n",
       "\n",
       "                                        action_point  rank  \\\n",
       "0  Champion a global narrative shift from economi...     1   \n",
       "1  Champion a global narrative shift from economi...     2   \n",
       "2  Champion a global narrative shift from economi...     3   \n",
       "3  Reform financial systems to support inclusive,...     1   \n",
       "4  Reform financial systems to support inclusive,...     2   \n",
       "\n",
       "                                        t20_sentence  \\\n",
       "0  Champion comprehensive ‘whole-of society, whol...   \n",
       "1  Operationalise the Global Alliance Against Hun...   \n",
       "2  Take actions to bring down the cost of capital...   \n",
       "3  Finance SDG Gaps through a Reform of the Globa...   \n",
       "4  In addition, strengthened South–South and Nort...   \n",
       "\n",
       "                                         t20_section     score  \n",
       "0  Accelerating Climate Action and the Just Energ...  0.487384  \n",
       "1  Solidarity for the Achievement of the Sustaina...  0.453438  \n",
       "2              Financing for Sustainable Development  0.425814  \n",
       "3  Solidarity for the Achievement of the Sustaina...  0.483550  \n",
       "4  Accelerating Climate Action and the Just Energ...  0.435472  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full run: all clusters, build DataFrame \n",
    "all_rows = []\n",
    "for cluster, ap_list in gss_clusters.items():\n",
    "    ap_emb = embed_texts(model, ap_list)\n",
    "    sims = cosine_similarity(ap_emb, t20_emb)\n",
    "    for ap_idx, ap in enumerate(ap_list):\n",
    "        top_idx = np.argsort(-sims[ap_idx])[:TOP_K]\n",
    "        for rank, ti in enumerate(top_idx, start=1):\n",
    "            all_rows.append({\n",
    "                \"cluster\": cluster,\n",
    "                \"ap_index\": ap_idx,\n",
    "                \"action_point\": ap,\n",
    "                \"rank\": rank,\n",
    "                \"t20_sentence\": t20_sentences[ti],\n",
    "                \"t20_section\": t20_sections[ti],\n",
    "                \"score\": float(sims[ap_idx][ti]),\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(all_rows)\n",
    "print(\"Results size:\", results_df.shape)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9640e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select onlz column 3 and 5 from results_df\n",
    "results_df_2 = results_df[[\"action_point\", \"t20_sentence\"]]\n",
    "\n",
    "#save csv\n",
    "#results_df_2.to_csv(\"gss_t20_similarity_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8bbc659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote HTML: /Users/fernandaortega/Library/CloudStorage/OneDrive-GlobalSolutionsInitiativeFoundationgGmbH/General/06_Program & Research/Recoupling Dashboard/Final-impact report/gss_t20_similarity.html\n"
     ]
    }
   ],
   "source": [
    "#  HTML report\n",
    "results_by_cluster = {}\n",
    "for cluster, df in results_df.groupby(\"cluster\"):\n",
    "    results_by_cluster[cluster] = df.copy()\n",
    "\n",
    "html = build_html(results_by_cluster)\n",
    "OUT_HTML.write_text(html, encoding=\"utf-8\")\n",
    "print(\"Wrote HTML:\", OUT_HTML.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0807513d",
   "metadata": {},
   "source": [
    "### Ontological topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51516c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected clusters: 6\n",
      " • Human Flourishing: 4 action points\n",
      " • Climate Action and Sustainability: 5 action points\n",
      " • Digital and AI Transformation: 5 action points\n",
      " • Geoeconomics and Trade: 4 action points\n",
      " • Global Finance: 4 action points\n",
      " • Global Governance and Multilateralism: 4 action points\n",
      "\n",
      "First cluster preview: Human Flourishing\n",
      " - Champion a global narrative shift from economic growth to human flourishing, grounded in equity, sustainability, and dignity.\n",
      " - Reform financial systems to support inclusive, long-term development.\n",
      " - Empower communities to co-create solutions, especially in the Global South, through grassroots innovation and development corridors\n",
      "T20 sentences: 62\n",
      "T20 sentence sample:\n",
      " - {'sentence': '1.1.', 'section': 'Trade and Investment'}\n",
      " - {'sentence': 'Empower the WTO to preserve and reform the multilateral trading system: The G20 should empower the WTO by strengthening the WTO Secretariat and making additional financial resources available.', 'section': 'Trade and Investment'}\n",
      " - {'sentence': 'The decision-making process should also be made more flexible, this will help advance and incorporate pro-development plurilateral agreements, such as the Investment Facilitation for Development (IFD) Agreement, into the WTO Framework.', 'section': 'Trade and Investment'}\n",
      " - {'sentence': 'The dispute settlement system needs to be reformed to strengthen deliberative processes and preventive mechanisms, in the interim building on the Multi-Party Interim Appeal Arbitration Arrangement (MPIA).', 'section': 'Trade and Investment'}\n",
      " - {'sentence': 'The Generalised System of Preferences (GSP) should be reviewed to provide predictable, longterm market access for services and flexible rules of origin for goods for Least Developed Countries (LDCs).', 'section': 'Trade and Investment'}\n",
      "Loaded SBERT: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built label embeddings for 63 topics; lexical index ready.\n",
      "T20 embedding shape: (62, 384)\n",
      "T20 topics sample: [('1.1.', []), ('Empower the WTO to preserve and reform the multilateral trading system: The G20 should empower the WTO by strengthening the WTO Secretariat and making additional financial resources available.', ['G20 Global Leadership', 'International cooperation', 'Finance reform', 'Economic empowerment', 'Trade facilitation', 'Equity']), ('The decision-making process should also be made more flexible, this will help advance and incorporate pro-development plurilateral agreements, such as the Investment Facilitation for Development (IFD) Agreement, into the WTO Framework.', ['International cooperation', 'Policy relevance', 'Green industrialisation'])]\n",
      "Results size: (78, 10)\n",
      "             cluster  ap_index  \\\n",
      "0  Human Flourishing         0   \n",
      "1  Human Flourishing         0   \n",
      "2  Human Flourishing         0   \n",
      "3  Human Flourishing         1   \n",
      "4  Human Flourishing         1   \n",
      "\n",
      "                                        action_point  \\\n",
      "0  Champion a global narrative shift from economi...   \n",
      "1  Champion a global narrative shift from economi...   \n",
      "2  Champion a global narrative shift from economi...   \n",
      "3  Reform financial systems to support inclusive,...   \n",
      "4  Reform financial systems to support inclusive,...   \n",
      "\n",
      "                                           ap_topics  rank  \\\n",
      "0  Well-Being Economy, Economic empowerment, Well...     1   \n",
      "1  Well-Being Economy, Economic empowerment, Well...     2   \n",
      "2  Well-Being Economy, Economic empowerment, Well...     3   \n",
      "3  Finance reform, Finance and investment mechani...     1   \n",
      "4  Finance reform, Finance and investment mechani...     2   \n",
      "\n",
      "                                        t20_sentence  \\\n",
      "0  Champion comprehensive ‘whole-of society, whol...   \n",
      "1  Operationalise the Global Alliance Against Hun...   \n",
      "2  Take actions to bring down the cost of capital...   \n",
      "3  Finance SDG Gaps through a Reform of the Globa...   \n",
      "4  In addition, strengthened South–South and Nort...   \n",
      "\n",
      "                                         t20_section  \\\n",
      "0  Accelerating Climate Action and the Just Energ...   \n",
      "1  Solidarity for the Achievement of the Sustaina...   \n",
      "2              Financing for Sustainable Development   \n",
      "3  Solidarity for the Achievement of the Sustaina...   \n",
      "4  Accelerating Climate Action and the Just Energ...   \n",
      "\n",
      "                                          t20_topics  \\\n",
      "0  Just transition, Inclusive governance, Interna...   \n",
      "1  International cooperation, Food systems, G20 G...   \n",
      "2  G20 Global Leadership, Finance reform, Finance...   \n",
      "3  Finance reform, Debt relief, Finance and inves...   \n",
      "4  Regional cooperation, Economic empowerment, In...   \n",
      "\n",
      "                                      overlap_topics     score  \n",
      "0  Economic empowerment, Equity, Well-Being Econo...  0.487384  \n",
      "1                   Economic empowerment, Well-being  0.453438  \n",
      "2                                                     0.425814  \n",
      "3  Debt relief, Finance and investment mechanisms...  0.483550  \n",
      "4                                 Well-Being Economy  0.435472  \n",
      "Wrote HTML: /Users/fernandaortega/Library/CloudStorage/OneDrive-GlobalSolutionsInitiativeFoundationgGmbH/General/06_Program & Research/Recoupling Dashboard/Final-impact report/gss_t20_similarity_report.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: divide by zero encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: overflow encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: invalid value encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: divide by zero encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: overflow encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: invalid value encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: divide by zero encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: overflow encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: invalid value encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: divide by zero encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: overflow encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: invalid value encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: divide by zero encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: overflow encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: invalid value encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: divide by zero encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: overflow encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/var/folders/zg/p4jqnvt16hn6hy997gwt3z7r0000gn/T/ipykernel_31705/2988727360.py:381: RuntimeWarning: invalid value encountered in matmul\n",
      "  sims = text_embs @ label_mat.T                           # cosine similarities\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/fernandaortega/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# GSS 2025 (Action Points) ↔ T20 (Sentence Recommendations)\n",
    "# (HTML export without Rank/Score; top filter by session)\n",
    "\n",
    "# %%\n",
    "# --- 0) Imports ---\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import docx\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# %%\n",
    "# --- 1) Config: paths, model, knobs ---\n",
    "# Edit these to your actual file locations\n",
    "PATH_ACTION_POINTS = Path(\"Action Points GSS 2025.docx\")\n",
    "PATH_T20           = Path(\"T20 communique.docx\")\n",
    "OUT_HTML           = Path(\"gss_t20_similarity_report.html\")\n",
    "\n",
    "SBERT_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "TOP_K       = 3  # top matches per AP\n",
    "\n",
    "# Topic labeling knobs\n",
    "TOPIC_THRESHOLD = 0.40   # similarity cutoff to accept a label (lower = more permissive)\n",
    "TOPIC_TOP_K    = 5       # max semantic labels to keep per text (lexical hits are added regardless)\n",
    "\n",
    "# %%\n",
    "# --- 2) Topic Ontology (edit/extend freely) ---\n",
    "TOPIC_ONTOLOGY: Dict[str, List[str]] = {\n",
    "    # Human flourishing / social\n",
    "    \"Well-being\": [\n",
    "        \"well-being\", \"wellbeing\", \"quality of life\", \"human flourishing\",\n",
    "        \"life satisfaction\", \"multidimensional well-being\", \"subjective well-being\",\n",
    "        \"whole-of-society\", \"poverty\"\n",
    "    ],\n",
    "    \"Equity\": [\n",
    "        \"equity\", \"equality\", \"social equity\", \"fairness\",\n",
    "        \"distributional justice\", \"inclusive growth\", \"inequalities\",\n",
    "        \"asymmetries\", \"Empower\"\n",
    "    ],\n",
    "    \"Vulnerable populations\": [\n",
    "        \"vulnerable groups\", \"vulnerable populations\", \"marginalised communities\",\n",
    "        \"at-risk groups\", \"refugees\", \"displaced persons\"\n",
    "    ],\n",
    "    \"Social protection\": [\n",
    "        \"social protection\", \"safety nets\", \"social protection floors\",\n",
    "        \"cash transfers\", \"universal access to social services\", \"protect worker\"\n",
    "    ],\n",
    "    \"Healthcare\": [\"healthcare\", \"health services\", \"health systems\"],\n",
    "    \"Education\": [\"education\", \"education system\", \"continuous education\"],\n",
    "    \"Gender equality\": [\"gender equality\", \"gender-responsive\", \"women empowerment\", \"gender and age responsive\"],\n",
    "    \"Youth participation\": [\"youth participation\", \"youth inclusion\", \"young people engagement\"],\n",
    "    \"Well-Being Economy\": [\n",
    "        \"well-being economy\", \"economy of well-being\", \"wellbeing economy\",\n",
    "        \"shift from economic growth\", \"whole-of-economy\", \"long-term development\",\n",
    "        \"inclusive governance frameworks\", \"economic transformation\"\n",
    "    ],\n",
    "\n",
    "    # Governance / participation / data\n",
    "    \"Inclusive governance\": [\n",
    "        \"inclusive governance\", \"participatory governance\", \"whole-of-society\",\n",
    "        \"whole-of-government\", \"community-led\", \"people-centred\"\n",
    "    ],\n",
    "    \"Policy relevance\": [\n",
    "        \"policy-relevant\", \"evidence-informed policy\", \"policy design\", \"policy evaluation\"\n",
    "    ],\n",
    "    \"Data governance\": [\n",
    "        \"data governance\", \"integrated data governance\", \"data interoperability\",\n",
    "        \"data standards\", \"algorithmic transparency\", \"data rights\"\n",
    "    ],\n",
    "    \"Institutional reform\": [\"institutional arrangements\", \"institutional reform\", \"restructuring systems\"],\n",
    "    \"Data rights and privacy\": [\n",
    "        \"data rights\", \"data control\", \"personal data\", \"privacy\",\n",
    "        \"privacy protection\", \"data protection\", \"GDPR\"\n",
    "    ],\n",
    "    \"Algorithmic transparency and accountability\": [\n",
    "        \"algorithmic decisions\", \"algorithmic transparency\", \"algorithmic accountability\",\n",
    "        \"explainable AI\", \"responsible AI\", \"AI accountability\"\n",
    "    ],\n",
    "    \"Open-source and civic tech\": [\n",
    "        \"open-source\", \"civic tech\", \"nonprofit platforms\", \"small developers\", \"public interest technology\"\n",
    "    ],\n",
    "    \"Digital public infrastructure (DPI)\": [\n",
    "        \"digital public infrastructure\", \"DPI\", \"people-first digital infrastructure\",\n",
    "        \"whole-of-society digital infrastructure\", \"sovereign digital systems\"\n",
    "    ],\n",
    "    \"Digital inclusion\": [\n",
    "        \"digital inclusion\", \"digital inequalities\", \"digital divide\", \"offline access\", \"ai literacy\"\n",
    "    ],\n",
    "    \"AI and human flourishing\": [\n",
    "        \"AI literacy\", \"reskilling\", \"worker rights\",\n",
    "        \"responsible AI\", \"human-centred AI\", \"AI for human capabilities\"\n",
    "    ],\n",
    "    \"Ethical tech and digital governance\": [\n",
    "        \"ethical tech\", \"tech safeguards\", \"ethical technology use\",\n",
    "        \"participatory digital governance\", \"civil society in digital governance\"\n",
    "    ],\n",
    "    \"Digital sovereignty and interoperability\": [\n",
    "        \"digital sovereignty\", \"sovereign digital systems\", \"global interoperability\", \"cross-border digital governance\"\n",
    "    ],\n",
    "    \"Digital economy and competition\": [\n",
    "        \"digital economy\", \"antitrust\", \"competition policy\",\n",
    "        \"collective bargaining\", \"platform power\", \"tech monopolies\"\n",
    "    ],\n",
    "    \"Data as a public good\": [\n",
    "        \"data as a public asset\", \"data commons\", \"community data\", \"public data governance\"\n",
    "    ],\n",
    "    \"Evidence-based digital policy\": [\n",
    "        \"digital statistics\", \"digital policy\", \"data for policy\", \"evidence-based digital policy\", \"digital metrics\"\n",
    "    ],\n",
    "    \"Global digital cooperation\": [\n",
    "        \"international cooperation on digital\", \"global digital forums\",\n",
    "        \"digital technology for sustainable development\", \"global digital governance\"\n",
    "    ],\n",
    "    \"AI literacy and skills\": [\n",
    "        \"AI literacy\", \"reskilling\", \"digital skills\", \"inclusive reskilling\", \"AI education\", \"capacity-building for AI\"\n",
    "    ],\n",
    "    \"Responsible and human-centred AI\": [\n",
    "        \"responsible AI\", \"human-centred AI\", \"AI for human flourishing\",\n",
    "        \"AI for human capabilities\", \"ethical AI\"\n",
    "    ],\n",
    "    \"AI governance and accountability\": [\n",
    "        \"AI governance\", \"AI regulation\", \"algorithmic accountability\", \"algorithmic transparency\", \"AI oversight\"\n",
    "    ],\n",
    "    \"Digital inclusion and equity\": [\n",
    "        \"digital inclusion\", \"digital inequalities\", \"equitable digital access\",\n",
    "        \"AI for inclusion\", \"support local innovation\"\n",
    "    ],\n",
    "    \"Skills development and capacity building\": [\n",
    "        \"skills development\", \"capacity-building\", \"education systems\", \"reskilling programs\",\n",
    "        \"knowledge sharing\", \"human capital\", \"strengthen capacity\", \"inclusive reskilling\", \"co-create solutions\"\n",
    "    ],\n",
    "    \"Technology transfer and cooperation\": [\n",
    "        \"technology transfer\", \"co-development of technology\"\n",
    "    ],\n",
    "    \"Social protection and digitalisation\": [\n",
    "        \"social protection systems\", \"universal access to services\",\n",
    "        \"healthcare and education access\", \"digitalisation and welfare\"\n",
    "    ],\n",
    "\n",
    "    # Climate / environment / transitions\n",
    "    \"Climate finance\": [\n",
    "        \"climate finance\", \"UNFCCC\", \"just transitions\",\n",
    "        \"climate-aligned investment\", \"low-carbon investment\"\n",
    "    ],\n",
    "    \"Just transition\": [\n",
    "        \"just transition\", \"transition taxonomies\", \"just transition policies\",\n",
    "        \"whole-of-society approach\", \"whole-of-government approach\", \"community-led\", \"just transitions\"\n",
    "    ],\n",
    "    \"Climate risk\": [\n",
    "        \"climate risk\", \"environmental risks\", \"biodiversity collapse\",\n",
    "        \"climate shocks\", \"climate vulnerability\"\n",
    "    ],\n",
    "    \"Biodiversity\": [\"biodiversity\"],\n",
    "    \"Bioeconomy\": [\n",
    "        \"bioeconomy\", \"climate-biodiversity nexus\",\n",
    "        \"nature-based solutions\", \"circular materials\", \"circular economy\",\n",
    "        \"nature positive\", \"nature credits\", \"ecosystem restoration\", \"nature finance\"\n",
    "    ],\n",
    "    \"Resilience\": [\n",
    "        \"resilience\", \"social resilience\", \"adaptive capacity\",\n",
    "        \"community resilience\", \"disaster preparedness\"\n",
    "    ],\n",
    "    \"Critical minerals\": [\n",
    "        \"critical minerals\", \"critical mineral value chains\",\n",
    "        \"fair benefit-sharing\", \"equitable green industrialisation\"\n",
    "    ],\n",
    "    \"Green industrialisation\": [\n",
    "        \"green industrialisation\", \"low-carbon development\",\n",
    "        \"industrial policy for green transition\", \"value chain integration\"\n",
    "    ],\n",
    "    \"Infrastructure transition\": [\n",
    "        \"energy grids\", \"digital infrastructure\", \"social infrastructure\", \"transport networks\"\n",
    "    ],\n",
    "    \"Nature finance\": [\n",
    "        \"nature finance\", \"nature credits\", \"biodiversity finance\",\n",
    "        \"environmental finance\", \"sustainable finance for ecosystems\"\n",
    "    ],\n",
    "    \"Food systems\": [\n",
    "        \"food systems\", \"equitable food systems\", \"hunger and poverty\",\n",
    "        \"agri-food systems\", \"sustainable food production\"\n",
    "    ],\n",
    "    \"Regional cooperation\": [\n",
    "        \"regional integration\", \"intra-regional trade\", \"regional cooperation\",\n",
    "        \"regional collaboration\", \"regional platforms\", \"regional partnerships\",\n",
    "        \"north-south collaboration\", \"south-south collaboration\"\n",
    "    ],\n",
    "    \"Collaboration and partnerships\": [\"collaboration\", \"partnerships\", \"joint efforts\"],\n",
    "\n",
    "    \"International cooperation\": [\n",
    "    \"international cooperation\", \"global cooperation\", \"multilateral cooperation\",\n",
    "    \"bilateral cooperation\", \"international partnerships\", \"global governance\",\n",
    "    \"cross-border collaboration\", \"transnational cooperation\", \n",
    "    \"international platforms\", \"international alliances\"\n",
    "    ],\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Finance / debt / investment\n",
    "    \"Finance reform\": [\n",
    "        \"financial system reform\", \"reform global finance\", \"financial institutions reform\",\n",
    "        \"sustainable finance\", \"reform the multilateral trading system\"\n",
    "    ],\n",
    "    \"Debt relief\": [\"debt relief\", \"debt swaps\", \"debt resolution\", \"debt sustainability\"],\n",
    "    \"Reduce cost of capital\": [\n",
    "        \"reduce cost of capital\", \"lower cost of capital\", \"cost of capital reduction\", \"cost of capital\"\n",
    "    ],\n",
    "    \"Progressive taxation\": [\"progressive fiscal policies\", \"wealth tax\", \"tax cooperation\", \"UN Tax Convention\"],\n",
    "    \"SDG financing\": [\"finance SDG gaps\", \"SDG financing\"],\n",
    "\n",
    "    # Trade / industrial policy / minerals\n",
    "    \"Trade facilitation\": [\n",
    "        \"trade rules\", \"trade cooperation\", \"interoperability of trade systems\", \"standards harmonisation\"\n",
    "    ],\n",
    "    \"Industrial policy and value addition\": [\n",
    "        \"industrial policy\", \"value addition\", \"domestic industrial development\", \"industrial upgrading\"\n",
    "    ],\n",
    "    \"Trade and sustainability\": [\"trade and sustainability\", \"environmental standards in trade\"],\n",
    "\n",
    "    # Infrastructure / innovation / tech\n",
    "    \"Infrastructure\": [\"infrastructure\", \"energy grids\", \"transport networks\", \"social infrastructure\", \"digital infrastructure\"],\n",
    "    \"Innovation & AI\": [\"ai tools\", \"data systems\", \"traceability systems\", \"technology co-development\"],\n",
    "    \"Circular economy\": [\"circular materials\", \"circular economy\"],\n",
    "\n",
    "    \"Private sector participation\": [\n",
    "        \"private capital\", \"mobilize private capital\", \"private sector investment\",\n",
    "        \"public-private partnerships\", \"PPP\", \"PPPs\", \"blended finance\",\n",
    "        \"crowding in private finance\", \"private sector participation\"\n",
    "    ],\n",
    "    \"Finance and investment mechanisms\": [\n",
    "        \"finance mechanisms\", \"financial instruments\", \"blended finance\",\n",
    "        \"impact bonds\", \"sustainable finance instruments\", \"outcome-focused finance\",\n",
    "        \"green bonds\", \"debt-for-nature swaps\", \"debt-for-SDG swaps\"\n",
    "    ],\n",
    "\n",
    "    \"Sustainability Standards & Measurement\": [\n",
    "        \"biodiversity measurement\", \"minerals governance framework\",\n",
    "        \"monitoring and reporting\", \"standards\"\n",
    "    ],\n",
    "\n",
    "    # Participation / accountability\n",
    "    \"Accountability & participation\": [\"accountability\", \"participation\", \"benefit-sharing\", \"community-led\", \"feedback loops\"],\n",
    "\n",
    "    # Empowerment / leadership\n",
    "    \"Economic empowerment\": [\n",
    "        \"economic empowerment\", \"empower communities\", \"transfer and co-development\", \"strengthen capacity in the Global South\"\n",
    "    ],\n",
    "    \"G20 Global Leadership\": [\"influence of G20\", \"G20 should\", \"G20 must\"]\n",
    "}\n",
    "\n",
    "# %%\n",
    "# --- 3) Utilities to read docs and parse ---\n",
    "def read_docx_paragraphs(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path.resolve()}\")\n",
    "    doc = docx.Document(str(path))\n",
    "    paras = [p.text.strip() for p in doc.paragraphs]\n",
    "    return [p for p in paras if p.strip()]\n",
    "\n",
    "def looks_like_cluster_header(line: str) -> bool:\n",
    "    if not line:\n",
    "        return False\n",
    "    if line.startswith(\"[\"):\n",
    "        return False\n",
    "    if line.lstrip().startswith(\"- \"):\n",
    "        return False\n",
    "    if re.match(r\"^\\d+(\\.|:)?\\s\", line):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def parse_gss_clusters(paragraphs):\n",
    "    clusters = defaultdict(list)\n",
    "    current_cluster = None\n",
    "    for line in paragraphs:\n",
    "        txt = line.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        if looks_like_cluster_header(txt) and not txt.startswith(\"[]\"):\n",
    "            current_cluster = txt\n",
    "            _ = clusters[current_cluster]\n",
    "            continue\n",
    "        if txt.startswith(\"[]\") or (\"[\" in txt and \"]\" in txt):\n",
    "            ap = re.sub(r\"^\\s*\\[\\s*\\]\\s*\", \"\", txt).strip()\n",
    "            if not current_cluster:\n",
    "                current_cluster = \"Ungrouped\"\n",
    "            if ap:\n",
    "                clusters[current_cluster].append(ap)\n",
    "    return {k: v for k, v in clusters.items() if v}\n",
    "\n",
    "def normalize_whitespace(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def split_t20_into_sentences(paragraphs):\n",
    "    sentences = []\n",
    "    current_section = None\n",
    "    for raw in paragraphs:\n",
    "        line = raw.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # treat title-ish lines as sections (no period at end)\n",
    "        if looks_like_cluster_header(line) and not line.endswith(\".\"):\n",
    "            current_section = line\n",
    "            continue\n",
    "        for s in sent_tokenize(line):\n",
    "            s = normalize_whitespace(s)\n",
    "            if len(s) >= 3:\n",
    "                sentences.append({\"sentence\": s, \"section\": current_section})\n",
    "    # dedupe\n",
    "    seen, out = set(), []\n",
    "    for row in sentences:\n",
    "        key = (row[\"sentence\"], row[\"section\"])\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            out.append(row)\n",
    "    return out\n",
    "\n",
    "# %%\n",
    "# --- 4) Embedding helpers ---\n",
    "def embed_texts(model, texts):\n",
    "    return model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "def build_topic_label_embeddings(model, ontology: Dict[str, List[str]]) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build a single embedding per label by averaging its seed phrase embeddings,\n",
    "    then re-normalize the mean vector to unit length (so dot==cosine).\n",
    "    \"\"\"\n",
    "    label_embs = {}\n",
    "    for label, seeds in ontology.items():\n",
    "        seed_embs = embed_texts(model, seeds)  # already normalized\n",
    "        mean_vec  = seed_embs.mean(axis=0)\n",
    "        norm = np.linalg.norm(mean_vec)\n",
    "        if norm > 0:\n",
    "            mean_vec = mean_vec / norm\n",
    "        label_embs[label] = mean_vec\n",
    "    return label_embs\n",
    "\n",
    "# %%\n",
    "# --- 5) Lexical fallback (regex) ---\n",
    "def build_lexicon_index(ontology: Dict[str, List[str]]):\n",
    "    \"\"\"\n",
    "    Compile regex for each seed phrase for fast, case-insensitive matching.\n",
    "    Uses word boundaries; also handles simple hyphen/space variants.\n",
    "    \"\"\"\n",
    "    idx = {}\n",
    "    for label, seeds in ontology.items():\n",
    "        pats = []\n",
    "        for s in seeds:\n",
    "            s_esc = re.escape(s).replace(r\"\\-\", r\"[-\\s]\")  # \"well-being\" ~ \"well being\"\n",
    "            pats.append(rf\"(?i)\\b{s_esc}\\b\")\n",
    "        idx[label] = [re.compile(p) for p in pats]\n",
    "    return idx\n",
    "\n",
    "def lexical_hits(text: str, lex_index) -> List[str]:\n",
    "    hits = []\n",
    "    for label, regs in lex_index.items():\n",
    "        if any(r.search(text) for r in regs):\n",
    "            hits.append(label)\n",
    "    return hits\n",
    "\n",
    "# %%\n",
    "# --- 6) Topic assignment (semantic + lexical union) ---\n",
    "def assign_topics(\n",
    "    texts: List[str],\n",
    "    model,\n",
    "    label_embs: Dict[str, np.ndarray],\n",
    "    threshold: float = TOPIC_THRESHOLD,\n",
    "    top_k: int = TOPIC_TOP_K,\n",
    "    lex_index=None\n",
    ") -> Tuple[List[List[str]], np.ndarray]:\n",
    "    labels = list(label_embs.keys())\n",
    "    label_mat = np.vstack([label_embs[l] for l in labels])   # (L, dim), normalized\n",
    "    text_embs = embed_texts(model, texts)                    # (N, dim), normalized\n",
    "    sims = text_embs @ label_mat.T                           # cosine similarities\n",
    "\n",
    "    topics_per_text = []\n",
    "    for i, txt in enumerate(texts):\n",
    "        # 1) semantic picks by cosine\n",
    "        idx_sorted = np.argsort(-sims[i])\n",
    "        sem = []\n",
    "        for j in idx_sorted:\n",
    "            if sims[i, j] >= threshold:\n",
    "                sem.append(labels[j])\n",
    "            if len(sem) >= top_k:\n",
    "                break\n",
    "\n",
    "        # 2) lexical picks (guaranteed if literal seed appears)\n",
    "        lex = lexical_hits(txt, lex_index) if lex_index is not None else []\n",
    "\n",
    "        # 3) union with semantic-first order, then lexical remainders\n",
    "        seen = set(sem)\n",
    "        merged = sem + [l for l in lex if l not in seen]\n",
    "\n",
    "        topics_per_text.append(merged)\n",
    "    return topics_per_text, sims\n",
    "\n",
    "# %%\n",
    "# --- 7) HTML builder (no rank/score; with top filter by cluster) ---\n",
    "def build_html(results_by_cluster):\n",
    "    clusters = list(results_by_cluster.keys())\n",
    "\n",
    "    css = \"\"\"\n",
    "    <style>\n",
    "      :root { --border:#e5e7eb; --muted:#555; --muted2:#444; --bg:#f8fafc; --badge:#eef2ff; --badgeText:#3730a3; }\n",
    "      body { font-family: system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif; margin: 24px; color: #111; }\n",
    "      h1 { font-size: 28px; margin-bottom: 8px; }\n",
    "      h2 { font-size: 22px; margin: 28px 0 8px; }\n",
    "      table { border-collapse: collapse; width: 100%; margin: 12px 0 28px 0; }\n",
    "      th, td { border: 1px solid var(--border); padding: 10px 12px; vertical-align: top; }\n",
    "      th { background: var(--bg); text-align: left; font-weight: 600; }\n",
    "      tr:nth-child(even) { background: #fafafa; }\n",
    "      .ap { font-weight: 600; }\n",
    "      .subtle { color: var(--muted); font-size: 12px; margin-top: 4px; }\n",
    "      .section { color: var(--muted2); font-size: 12px; margin-top: 4px; }\n",
    "      .cluster-badge { display:inline-block; background:var(--badge); color:var(--badgeText); padding:4px 8px; border-radius:12px; font-size:12px; margin-left:6px; }\n",
    "      .chip { display:inline-block; padding:2px 8px; margin:2px 4px 0 0; border:1px solid var(--border); border-radius:999px; font-size:12px; background:var(--bg); }\n",
    "      .toolbar { display:flex; gap:12px; align-items:center; padding:12px; border:1px solid var(--border); border-radius:12px; background:#fff; margin: 12px 0 20px; position:sticky; top:0; z-index:5; }\n",
    "      .toolbar label { font-size:14px; color:#111; }\n",
    "      .toolbar select { padding:8px 10px; border:1px solid var(--border); border-radius:10px; }\n",
    "      .toolbar button { padding:8px 12px; border:1px solid var(--border); border-radius:10px; background:#111; color:#fff; cursor:pointer; }\n",
    "      .toolbar button:hover { opacity:0.9; }\n",
    "      .footer { margin-top: 40px; color: #666; font-size: 12px; }\n",
    "      section.cluster { margin-bottom: 28px; }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "    js = \"\"\"\n",
    "    <script>\n",
    "      function applyClusterFilter() {\n",
    "        var sel = document.getElementById('clusterSelect').value;\n",
    "        var secs = document.querySelectorAll('section.cluster');\n",
    "        secs.forEach(function(sec){\n",
    "          if (sel === 'ALL' || sec.dataset.cluster === sel) {\n",
    "            sec.style.display = '';\n",
    "          } else {\n",
    "            sec.style.display = 'none';\n",
    "          }\n",
    "        });\n",
    "        window.scrollTo({top:0, behavior:'smooth'});\n",
    "      }\n",
    "      document.addEventListener('DOMContentLoaded', function(){\n",
    "        var sel = document.getElementById('clusterSelect');\n",
    "        if (sel) {\n",
    "          sel.addEventListener('keydown', function(e){\n",
    "            if (e.key === 'Enter') applyClusterFilter();\n",
    "          });\n",
    "        }\n",
    "      });\n",
    "    </script>\n",
    "    \"\"\"\n",
    "\n",
    "    html = [f\"<!DOCTYPE html><html><head><meta charset='utf-8'><title>GSS–T20 Similarity</title>{css}{js}</head><body>\"]\n",
    "    html.append(\"<h1>GSS 2025 Action Points ↔ T20 Recommendations</h1>\")\n",
    "\n",
    "    # Toolbar with cluster filter\n",
    "    html.append(\"<div class='toolbar'>\")\n",
    "    html.append(\"<label for='clusterSelect'>Filter by GSS cluster:</label>\")\n",
    "    html.append(\"<select id='clusterSelect' aria-label='Filter by GSS session'>\")\n",
    "    html.append(\"<option value='ALL'>Show all</option>\")\n",
    "    for c in clusters:\n",
    "        c_opt = str(c).replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
    "        html.append(f\"<option value='{c_opt}'>{c_opt}</option>\")\n",
    "    html.append(\"</select>\")\n",
    "    html.append(\"<button onclick='applyClusterFilter()'>Apply</button>\")\n",
    "    html.append(\"</div>\")\n",
    "\n",
    "    # Cluster sections (no Rank/Score columns)\n",
    "    for cluster, df in results_by_cluster.items():\n",
    "        cluster_safe = str(cluster).replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
    "        html.append(f\"<section class='cluster' data-cluster='{cluster_safe}'>\")\n",
    "        html.append(f\"<h2>{cluster_safe} <span class='cluster-badge'>Top matches</span></h2>\")\n",
    "        html.append(\"<table>\")\n",
    "        html.append(\"<tr><th style='width:34%'>GSS Action Point</th><th>Match (T20 Recommendation)</th><th style='width:24%'>Overlap topics</th></tr>\")\n",
    "\n",
    "        last_ap_idx = None\n",
    "        for _, r in df.sort_values([\"ap_index\", \"rank\"]).iterrows():\n",
    "            ap_cell = \"\"\n",
    "            if r[\"ap_index\"] != last_ap_idx:\n",
    "                ap_cell = f\"<div class='ap'>{r['action_point']}</div>\"\n",
    "                if 'ap_topics' in r and isinstance(r['ap_topics'], str) and r['ap_topics'].strip():\n",
    "                    ap_cell += f\"<div class='subtle'>AP topics: {r['ap_topics']}</div>\"\n",
    "                last_ap_idx = r[\"ap_index\"]\n",
    "\n",
    "            # T20 cell with section + topics\n",
    "            t20_cell = f\"{r['t20_sentence']}\"\n",
    "            section_badge = (\n",
    "                f\"<div class='section'>Section: {r['t20_section']}</div>\"\n",
    "                if pd.notna(r['t20_section']) and r['t20_section'] else \"\"\n",
    "            )\n",
    "            t20_cell += section_badge\n",
    "            if 't20_topics' in r and isinstance(r['t20_topics'], str) and r['t20_topics'].strip():\n",
    "                t20_cell += f\"<div class='subtle'>T20 topics: {r['t20_topics']}</div>\"\n",
    "\n",
    "            # overlap chips\n",
    "            chips = \"\"\n",
    "            if 'overlap_topics' in r and isinstance(r['overlap_topics'], str) and r['overlap_topics'].strip():\n",
    "                chips = \"\".join([f\"<span class='chip'>{t.strip()}</span>\" for t in r['overlap_topics'].split(\",\") if t.strip()])\n",
    "\n",
    "            html.append(\n",
    "                \"<tr>\"\n",
    "                f\"<td>{ap_cell}</td>\"\n",
    "                f\"<td>{t20_cell}</td>\"\n",
    "                f\"<td>{chips}</td>\"\n",
    "                \"</tr>\"\n",
    "            )\n",
    "        html.append(\"</table>\")\n",
    "        html.append(\"</section>\")\n",
    "\n",
    "    html.append(\"<div class='footer'>Model: SentenceTransformer ‘all-MiniLM-L6-v2’.</div>\")\n",
    "    html.append(\"</body></html>\")\n",
    "    return \"\\n\".join(html)\n",
    "\n",
    "# %%\n",
    "# --- 8) Read inputs ---\n",
    "gss_paragraphs = read_docx_paragraphs(PATH_ACTION_POINTS)\n",
    "t20_paragraphs = read_docx_paragraphs(PATH_T20)\n",
    "\n",
    "# %%\n",
    "# --- 9) Parse clusters and action points (checkpoint) ---\n",
    "gss_clusters = parse_gss_clusters(gss_paragraphs)\n",
    "print(f\"Detected clusters: {len(gss_clusters)}\")\n",
    "for k, v in gss_clusters.items():\n",
    "    print(f\" • {k}: {len(v)} action points\")\n",
    "\n",
    "first_cluster = next(iter(gss_clusters)) if gss_clusters else None\n",
    "if first_cluster:\n",
    "    print(\"\\nFirst cluster preview:\", first_cluster)\n",
    "    for ap in gss_clusters[first_cluster][:3]:\n",
    "        print(\" -\", ap)\n",
    "\n",
    "# %%\n",
    "# --- 10) Split T20 into sentences (checkpoint) ---\n",
    "t20_sent_rows = split_t20_into_sentences(t20_paragraphs)\n",
    "print(f\"T20 sentences: {len(t20_sent_rows)}\")\n",
    "print(\"T20 sentence sample:\")\n",
    "for r in t20_sent_rows[:5]:\n",
    "    print(\" -\", r)\n",
    "\n",
    "# %%\n",
    "# --- 11) Load Sentence-BERT model + build ontology embeddings + lexical index ---\n",
    "model = SentenceTransformer(SBERT_MODEL)\n",
    "print(\"Loaded SBERT:\", SBERT_MODEL)\n",
    "\n",
    "label_embeddings = build_topic_label_embeddings(model, TOPIC_ONTOLOGY)\n",
    "lex_index = build_lexicon_index(TOPIC_ONTOLOGY)\n",
    "print(f\"Built label embeddings for {len(label_embeddings)} topics; lexical index ready.\")\n",
    "\n",
    "# %%\n",
    "# --- 12) Embed T20 sentences + label topics (checkpoint) ---\n",
    "t20_sentences = [r[\"sentence\"] for r in t20_sent_rows]\n",
    "t20_sections  = [r[\"section\"]  for r in t20_sent_rows]\n",
    "t20_emb = embed_texts(model, t20_sentences)\n",
    "print(\"T20 embedding shape:\", t20_emb.shape)\n",
    "\n",
    "t20_topics, _t20_topic_sims = assign_topics(\n",
    "    t20_sentences, model, label_embeddings,\n",
    "    threshold=TOPIC_THRESHOLD, top_k=TOPIC_TOP_K,\n",
    "    lex_index=lex_index\n",
    ")\n",
    "print(\"T20 topics sample:\", list(zip(t20_sentences[:3], t20_topics[:3])))\n",
    "\n",
    "# %%\n",
    "# --- 13) Full run: all clusters, build DataFrame (checkpoint) ---\n",
    "all_rows = []\n",
    "for cluster, ap_list in gss_clusters.items():\n",
    "    # topics for APs in this cluster\n",
    "    ap_topics, _ap_topic_sims = assign_topics(\n",
    "        ap_list, model, label_embeddings,\n",
    "        threshold=TOPIC_THRESHOLD, top_k=TOPIC_TOP_K,\n",
    "        lex_index=lex_index\n",
    "    )\n",
    "\n",
    "    # embeddings + sims\n",
    "    ap_emb = embed_texts(model, ap_list)\n",
    "    sims = cosine_similarity(ap_emb, t20_emb)\n",
    "\n",
    "    for ap_idx, ap in enumerate(ap_list):\n",
    "        top_idx = np.argsort(-sims[ap_idx])[:TOP_K]\n",
    "        for rank, ti in enumerate(top_idx, start=1):\n",
    "            overlap = sorted(set(ap_topics[ap_idx]) & set(t20_topics[ti]))\n",
    "            all_rows.append({\n",
    "                \"cluster\": cluster,\n",
    "                \"ap_index\": ap_idx,\n",
    "                \"action_point\": ap,\n",
    "                \"ap_topics\": \", \".join(ap_topics[ap_idx]),\n",
    "                \"rank\": rank,  # kept for sorting only; not displayed in HTML\n",
    "                \"t20_sentence\": t20_sentences[ti],\n",
    "                \"t20_section\": t20_sections[ti],\n",
    "                \"t20_topics\": \", \".join(t20_topics[ti]),\n",
    "                \"overlap_topics\": \", \".join(overlap),\n",
    "                \"score\": float(sims[ap_idx][ti]),  # kept for potential diagnostics\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(all_rows)\n",
    "print(\"Results size:\", results_df.shape)\n",
    "print(results_df.head())\n",
    "\n",
    "# %%\n",
    "# --- 14) Build & write HTML report ---\n",
    "results_by_cluster = {c: df.copy() for c, df in results_df.groupby(\"cluster\")}\n",
    "html = build_html(results_by_cluster)\n",
    "OUT_HTML.write_text(html, encoding=\"utf-8\")\n",
    "print(\"Wrote HTML:\", OUT_HTML.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
